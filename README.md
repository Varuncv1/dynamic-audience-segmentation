# Dynamic Audience Segmentation via Online Clustering

An end-to-end prototype for real-time audience segmentation using online clustering algorithms. Ingest sessionized clickstream or transaction data, extract features on the fly, and cluster each user session incrementally with both River and scikit-learn models.

---

## ğŸš€ Features

* **Streaming Simulation**
  Read pre-processed session data in small batches to mimic real-time arrival.
* **Feature Engineering**
  Session-level metrics: total items, total value, unique products, session duration, hour of day.
* **Multiple Clustering Models**

  * **River KMeans** for fully online, one-observation-at-a-time learning
  * **scikit-learn MiniBatchKMeans** for batch-based incremental updates
  * *(Optional)* River DenStream for density-based clustering (commented out)
* **Visualization**
  Centroid drift plots to monitor how clusters evolve over time.
* **Modular Codebase**
  Clean separation of streaming, feature engineering, modeling, visualization, and configuration.

---

## ğŸ“ Directory Structure

```
dynamic-audience-segmentation/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # raw source files (e.g. online_retail.xlsx)
â”‚   â””â”€â”€ processed/            # cleaned & sessionized CSVs
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ prototyping_final.ipynb  # end-to-end prototype flow
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py             # hyperparameters & file paths
â”‚   â”œâ”€â”€ main.py               # orchestrates streaming â†’ clustering â†’ viz
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ stream.py         # batch generator for streaming sessions
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ engineer.py       # extract_features() function
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ online_cluster.py # OnlineClustering wrapper with multiple algorithms
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ viz.py            # centroid drift plotting
â”‚       â””â”€â”€ metrics.py        # optional evaluation helpers
â”‚
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                 # this file
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Prerequisites

* Python 3.8 or later
* `virtualenv` or `venv` for environment isolation

---

## ğŸ“¥ Installation

1. **Clone the repo**

   ```bash
   git clone https://your.repo.url/dynamic-audience-segmentation.git
   cd dynamic-audience-segmentation
   ```

2. **Create and activate a virtual environment**

   ```bash
   python3 -m venv venv
   source venv/bin/activate        # macOS/Linux
   venv\Scripts\activate.bat       # Windows
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸƒâ€â™‚ï¸ Usage

### 1. Prepare your data

* Place your raw Excel file in `data/raw/online_retail.xlsx`.
* Run the notebook to clean, sessionize, and export to `data/processed/sessions.csv`:

  1. Launch Jupyter:

     ```bash
     jupyter lab
     ```
  2. Open `notebooks/prototyping_final.ipynb` and execute all cells.

### 2. Run the prototype script

```bash
python src/main.py
```

* Streams your session CSV in batches.
* Fits River KMeans and MiniBatchKMeans incrementally.
* Renders centroid drift plots at the end.

---

## ğŸ”§ Configuration

All â€œknobsâ€ live in `src/config.py`:

* `STREAM_BATCH_SIZE` & `STREAM_SLEEP_SEC`
* `N_CLUSTERS`
* `PROCESSED_DATA_PATH`

Tweak these constants to suit your data volume and experimenting pace.

---

## ğŸ“ˆ Next Steps & Extensions

* **Real Data Streams**: Swap `stream_batches()` to read from Kafka, Kinesis, or Pub/Sub.
* **Additional Models**: Plug in other River algorithms (e.g. DenStream, DBSTREAM) or online neural nets.
* **Dashboard**: Build a Streamlit or Dash UI to visualize clusters, segment composition, and concept drift live.
* **Evaluation & Alerts**: Integrate silhouette scoring, waterfall charts, or drift detectors with email or Slack notifications.

